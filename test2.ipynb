{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a22374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.scipy.special import logsumexp\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63eb569b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(512, 784), (512,)], [(256, 512), (256,)], [(10, 256), (10,)]]\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "\n",
    "\n",
    "def init_MLP(parkey, layer_widths, scale = 0.01):\n",
    "    params = []\n",
    "    keys = jax.random.split(parkey, num=len(layer_widths)-1)\n",
    "    for in_width, out_width, key in zip(layer_widths[:-1],layer_widths[1:], keys):\n",
    "        wkey, bkey = jax.random.split(key)\n",
    "        params.append([scale*jax.random.normal(wkey, shape=(out_width,in_width)),scale*jax.random.normal(bkey, shape=(out_width))])\n",
    "\n",
    "    return params\n",
    "\n",
    "\n",
    "key = jax.random.PRNGKey(seed)\n",
    "MLP_params = init_MLP(key, [784,512,256,10])\n",
    "print(jax.tree.map(lambda x: x.shape, MLP_params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c7bda25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 10)\n"
     ]
    }
   ],
   "source": [
    "# @jax.jit\n",
    "def predict(params, x):\n",
    "    # print(\"hi\")\n",
    "    hidden_layers = params[:-1]\n",
    "\n",
    "    activation = x\n",
    "    for w, b in hidden_layers:\n",
    "        activation = jax.nn.relu(jnp.dot(w, activation) + b)\n",
    "\n",
    "    w_last, b_last = params[-1]\n",
    "\n",
    "    logits = jnp.dot(w_last, activation) + b_last\n",
    "\n",
    "    return logits - logsumexp(logits)\n",
    "\n",
    "dummy_img_flat = np.random.randn(16, 784)\n",
    "\n",
    "prediction = jax.vmap(predict, in_axes=(None, 0))(MLP_params, dummy_img_flat)\n",
    "batch_predict = jax.vmap(predict, in_axes=(None, 0))\n",
    "# prediction = jax.vmap(predict, in_axes=(None, 1))(MLP_params, dummy_img_flat)\n",
    "print(prediction.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1798d414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n"
     ]
    }
   ],
   "source": [
    "def custom_collate(batch):\n",
    "    transposed_data = list(zip(*batch))\n",
    "    # print((transposed_data))\n",
    "\n",
    "    imgs = np.array(transposed_data[0])\n",
    "    labels = np.array(transposed_data[1])\n",
    "\n",
    "    # print(len(imgs))\n",
    "\n",
    "    return imgs, labels\n",
    "\n",
    "\n",
    "train_dataset = MNIST(root='./train_mnist',train=True, download=True,transform=lambda x: np.ravel(np.array(x, dtype=np.float32)))\n",
    "test_dataset = MNIST(root='./test_mnist',train=False, download=True,transform=lambda x: np.ravel(np.array(x, dtype=np.float32)))\n",
    "# print(type(train_dataset))\n",
    "# print((train_dataset[0][0].shape))\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=custom_collate)\n",
    "\n",
    "batch_data = next(iter(train_loader))\n",
    "print(len(batch_data[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd2ac5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.034985673\n",
      "0.030251497\n",
      "0.015898306\n",
      "0.027458886\n",
      "0.01796588\n",
      "0.015383233\n",
      "0.012061434\n",
      "0.03117384\n",
      "0.040019322\n",
      "0.019851575\n",
      "0.009944989\n",
      "0.02219074\n",
      "0.021367017\n",
      "0.029891139\n",
      "0.017947875\n",
      "0.02304166\n",
      "0.03506242\n",
      "0.030132512\n",
      "0.032620814\n",
      "0.04325784\n",
      "0.033331152\n",
      "0.016994527\n",
      "0.01829738\n",
      "0.03180411\n",
      "0.033397105\n",
      "0.026375938\n",
      "0.037283655\n",
      "0.016214786\n",
      "0.019808222\n",
      "0.023359388\n",
      "0.028543223\n",
      "0.022539264\n",
      "0.027493984\n",
      "0.028903132\n",
      "0.035730515\n",
      "0.013779183\n",
      "0.011998841\n",
      "0.020292196\n",
      "0.022780454\n",
      "0.013053355\n",
      "0.020621426\n",
      "0.021685978\n",
      "0.034751084\n",
      "0.020720262\n",
      "0.03930826\n",
      "0.023384405\n",
      "0.021060808\n",
      "0.03641354\n",
      "0.02548731\n",
      "0.018885398\n",
      "0.024537155\n",
      "0.022366678\n",
      "0.02661773\n",
      "0.03961853\n",
      "0.0203943\n",
      "0.021237403\n",
      "0.022857346\n",
      "0.017862849\n",
      "0.024456888\n",
      "0.027587492\n",
      "0.027551262\n",
      "0.031196887\n",
      "0.026749391\n",
      "0.029305452\n",
      "0.021211242\n",
      "0.017546715\n",
      "0.02685385\n",
      "0.02631746\n",
      "0.016128778\n",
      "0.019181807\n",
      "0.018716136\n",
      "0.030002391\n",
      "0.031723198\n",
      "0.024329623\n",
      "0.027736623\n",
      "0.020719036\n",
      "0.026990367\n",
      "0.031531096\n",
      "0.024753598\n",
      "0.03018405\n",
      "0.0380037\n",
      "0.0359079\n",
      "0.020102404\n",
      "0.028484423\n",
      "0.023890516\n",
      "0.024919815\n",
      "0.02965316\n",
      "0.022582268\n",
      "0.026102697\n",
      "0.024299657\n",
      "0.01929566\n",
      "0.029925657\n",
      "0.027039105\n",
      "0.023364333\n",
      "0.026106764\n",
      "0.023905262\n",
      "0.0221588\n",
      "0.027652634\n",
      "0.024262015\n",
      "0.030407041\n",
      "0.021057107\n",
      "0.02283234\n",
      "0.019904763\n",
      "0.02953198\n",
      "0.019173099\n",
      "0.018037662\n",
      "0.02552082\n",
      "0.023671178\n",
      "0.026669769\n",
      "0.026002174\n",
      "0.018719302\n",
      "0.018702904\n",
      "0.021178378\n",
      "0.018508365\n",
      "0.01744318\n",
      "0.016116356\n",
      "0.020259133\n",
      "0.020005224\n",
      "0.028942818\n",
      "0.023685591\n",
      "0.029088423\n",
      "0.023314679\n",
      "0.02501897\n",
      "0.019913137\n",
      "0.025857842\n",
      "0.015624128\n",
      "0.030125117\n",
      "0.030659094\n",
      "0.019481223\n",
      "0.017485736\n",
      "0.027501393\n",
      "0.021686215\n",
      "0.02762623\n",
      "0.015278853\n",
      "0.031731423\n",
      "0.03954022\n",
      "0.031720586\n",
      "0.024615401\n",
      "0.022440497\n",
      "0.020454967\n",
      "0.03176145\n",
      "0.018564554\n",
      "0.012304249\n",
      "0.02671947\n",
      "0.017603664\n",
      "0.031882323\n",
      "0.022947863\n",
      "0.022434417\n",
      "0.03677341\n",
      "0.022998232\n",
      "0.018782958\n",
      "0.015186592\n",
      "0.01732776\n",
      "0.022950582\n",
      "0.028329259\n",
      "0.02836111\n",
      "0.025798533\n",
      "0.019344453\n",
      "0.030848509\n",
      "0.025807416\n",
      "0.023674197\n",
      "0.019824434\n",
      "0.029614497\n",
      "0.036280606\n",
      "0.038172178\n",
      "0.02866376\n",
      "0.024459979\n",
      "0.018473541\n",
      "0.016789503\n",
      "0.03760985\n",
      "0.03876957\n",
      "0.02454629\n",
      "0.042212855\n",
      "0.033677317\n",
      "0.023722187\n",
      "0.031369325\n",
      "0.018436357\n",
      "0.027855087\n",
      "0.025943791\n",
      "0.029174587\n",
      "0.025443768\n",
      "0.019227339\n",
      "0.015934661\n",
      "0.023480875\n",
      "0.022337401\n",
      "0.028273625\n",
      "0.020664152\n",
      "0.018436769\n",
      "0.028443366\n",
      "0.022718264\n",
      "0.02988096\n",
      "0.017468642\n",
      "0.022144174\n",
      "0.022124052\n",
      "0.024870787\n",
      "0.031521227\n",
      "0.029017502\n",
      "0.023624936\n",
      "0.020858666\n",
      "0.024750749\n",
      "0.021213494\n",
      "0.030737136\n",
      "0.020624897\n",
      "0.020840006\n",
      "0.019345798\n",
      "0.02141611\n",
      "0.03327647\n",
      "0.025361998\n",
      "0.009360634\n",
      "0.025724977\n",
      "0.02821034\n",
      "0.032621693\n",
      "0.02052171\n",
      "0.02313421\n",
      "0.023241112\n",
      "0.023121176\n",
      "0.026640719\n",
      "0.026399512\n",
      "0.02255277\n",
      "0.02092784\n",
      "0.0184492\n",
      "0.019562842\n",
      "0.024631856\n",
      "0.041993324\n",
      "0.021708142\n",
      "0.02360453\n",
      "0.02294223\n",
      "0.02647605\n",
      "0.029949782\n",
      "0.028498141\n",
      "0.021712925\n",
      "0.016328994\n",
      "0.02165786\n",
      "0.016909216\n",
      "0.019554257\n",
      "0.024479166\n",
      "0.014397827\n",
      "0.014946553\n",
      "0.027662892\n",
      "0.028864348\n",
      "0.019656667\n",
      "0.019764517\n",
      "0.024832\n",
      "0.031853277\n",
      "0.026843606\n",
      "0.021166727\n",
      "0.01645231\n",
      "0.017901948\n",
      "0.031583466\n",
      "0.014544847\n",
      "0.023200778\n",
      "0.018112576\n",
      "0.03045823\n",
      "0.017264863\n",
      "0.02013204\n",
      "0.026113665\n",
      "0.020930832\n",
      "0.013331214\n",
      "0.019912055\n",
      "0.0285193\n",
      "0.023124557\n",
      "0.027827604\n",
      "0.02563271\n",
      "0.020503515\n",
      "0.02321933\n",
      "0.010959551\n",
      "0.022724165\n",
      "0.022747977\n",
      "0.01433822\n",
      "0.025893828\n",
      "0.024893954\n",
      "0.015493745\n",
      "0.024790883\n",
      "0.025853807\n",
      "0.027767736\n",
      "0.022881063\n",
      "0.023130339\n",
      "0.030135129\n",
      "0.029352522\n",
      "0.025478948\n",
      "0.037486933\n",
      "0.029122725\n",
      "0.026086131\n",
      "0.008242539\n",
      "0.03594633\n",
      "0.020366758\n",
      "0.02877423\n",
      "0.018385237\n",
      "0.0128002735\n",
      "0.033889588\n",
      "0.020908441\n",
      "0.016326731\n",
      "0.017179947\n",
      "0.02644883\n",
      "0.024661016\n",
      "0.022121375\n",
      "0.021251503\n",
      "0.035391904\n",
      "0.021867245\n",
      "0.019868089\n",
      "0.017183688\n",
      "0.018907636\n",
      "0.020491375\n",
      "0.01806658\n",
      "0.029435178\n",
      "0.021895643\n",
      "0.027053444\n",
      "0.020980392\n",
      "0.020186236\n",
      "0.017748795\n",
      "0.021280814\n",
      "0.017250363\n",
      "0.019976357\n",
      "0.023476364\n",
      "0.019494463\n",
      "0.026099091\n",
      "0.02708673\n",
      "0.030028153\n",
      "0.037802972\n",
      "0.023957746\n",
      "0.017021827\n",
      "0.031184057\n",
      "0.02412354\n",
      "0.018232737\n",
      "0.031790543\n",
      "0.027352357\n",
      "0.02518881\n",
      "0.037757225\n",
      "0.022221303\n",
      "0.017430784\n",
      "0.013227251\n",
      "0.030621067\n",
      "0.01772559\n",
      "0.029164314\n",
      "0.029897828\n",
      "0.033569008\n",
      "0.02055741\n",
      "0.024941826\n",
      "0.015164735\n",
      "0.017979411\n",
      "0.024282893\n",
      "0.026046926\n",
      "0.029077888\n",
      "0.026111186\n",
      "0.022294125\n",
      "0.023530712\n",
      "0.017405024\n",
      "0.020033661\n",
      "0.029218143\n",
      "0.02349347\n",
      "0.025227327\n",
      "0.013629851\n",
      "0.019435579\n",
      "0.024257144\n",
      "0.03203806\n",
      "0.016621454\n",
      "0.02533384\n",
      "0.020411193\n",
      "0.015351265\n",
      "0.012436337\n",
      "0.025085136\n",
      "0.022060404\n",
      "0.021595664\n",
      "0.01740493\n",
      "0.022212565\n",
      "0.015817937\n",
      "0.025328085\n",
      "0.0294918\n",
      "0.027131295\n",
      "0.011662024\n",
      "0.024279926\n",
      "0.036813002\n",
      "0.03334747\n",
      "0.022557303\n",
      "0.024631558\n",
      "0.029657632\n",
      "0.021769201\n",
      "0.019192833\n",
      "0.023020366\n",
      "0.025868675\n",
      "0.0228295\n",
      "0.030713964\n",
      "0.025903357\n",
      "0.01417383\n",
      "0.020156011\n",
      "0.022588797\n",
      "0.03002494\n",
      "0.011939866\n",
      "0.022754442\n",
      "0.027024765\n",
      "0.027376352\n",
      "0.018484874\n",
      "0.023436597\n",
      "0.02214915\n",
      "0.023580829\n",
      "0.019957354\n",
      "0.013788238\n",
      "0.022247111\n",
      "0.016971646\n",
      "0.01771612\n",
      "0.015606451\n",
      "0.018753171\n",
      "0.02612474\n",
      "0.020858664\n",
      "0.014049107\n",
      "0.021621138\n",
      "0.021036375\n",
      "0.023227355\n",
      "0.022158122\n",
      "0.013914624\n",
      "0.030920997\n",
      "0.02558747\n",
      "0.01050017\n",
      "0.015106872\n",
      "0.0254833\n",
      "0.012847969\n",
      "0.015655225\n",
      "0.023338864\n",
      "0.017913358\n",
      "0.019246165\n",
      "0.013177811\n",
      "0.016796852\n",
      "0.03193257\n",
      "0.02235852\n",
      "0.031006051\n",
      "0.029429436\n",
      "0.02533317\n",
      "0.016773334\n",
      "0.022027377\n",
      "0.023758834\n",
      "0.02512293\n",
      "0.013668886\n",
      "0.023427382\n",
      "0.035556447\n",
      "0.015641583\n",
      "0.022193575\n",
      "0.032512374\n",
      "0.025691533\n",
      "0.031743098\n",
      "0.023810202\n",
      "0.025362862\n",
      "0.018317765\n",
      "0.03395179\n",
      "0.020994548\n",
      "0.02621379\n",
      "0.018402914\n",
      "0.0257009\n",
      "0.027126003\n",
      "0.019261613\n",
      "0.021484418\n",
      "0.024314305\n",
      "0.025038702\n",
      "0.02067665\n",
      "0.026207967\n",
      "0.020924658\n",
      "0.017587636\n",
      "0.011185504\n",
      "0.021468544\n",
      "0.014685712\n",
      "0.011864618\n",
      "0.020094529\n",
      "0.029519254\n",
      "0.016410938\n",
      "0.023374818\n",
      "0.035835188\n",
      "0.011200371\n",
      "0.02174827\n",
      "0.020544589\n",
      "0.017458797\n"
     ]
    }
   ],
   "source": [
    "from jax import grad, value_and_grad\n",
    "\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "def loss(params, imgs, gt_labels):\n",
    "    output = batch_predict(params, imgs)\n",
    "    return -jnp.mean(output*gt_labels)\n",
    "\n",
    "def update(params, imgs, gt_labels, lr=0.01):\n",
    "    l, grads = value_and_grad(loss)(params,imgs,gt_labels)\n",
    "    return l, jax.tree.map(lambda p, g: p - lr*g, params, grads)\n",
    "\n",
    "for epoch in range((NUM_EPOCHS)):\n",
    "\n",
    "    for cnt, (imgs, labels) in enumerate(train_loader):\n",
    "        gt_labels = jax.nn.one_hot(labels,len(MNIST.classes))\n",
    "        l, MLP_params = update(MLP_params, imgs, gt_labels)\n",
    "\n",
    "        # if cnt % 50 == 0:\n",
    "        print(l)\n",
    "    break\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
